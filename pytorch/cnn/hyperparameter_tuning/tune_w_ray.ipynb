{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install 'ray[tune]' --quiet\n",
    "# ! pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, l1=128, l2=64):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1), \n",
    "            nn.Flatten(), \n",
    "            nn.Linear(26*26*4, l1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(l1, l2),\n",
    "            nn.Linear(l2, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        logits = self.cnn(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir='/Users/yujian/Documents/personal-workspace/nn_examples/pytorch/fashion_mnist'):\n",
    "    trainset = datasets.FashionMNIST(root=dir, train=True, transform=transforms.ToTensor())\n",
    "    testset = datasets.FashionMNIST(root=dir, train=False, transform=transforms.ToTensor())\n",
    "    return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(config, checkpoint_dir=None, data_dir=None):\n",
    "    model = NeuralNetwork(config[\"l1\"], config[\"l2\"])\n",
    "    learning_rate = 1e-3\n",
    "    batchsize=64\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    device = 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "    \n",
    "    training_data, testing_data = load_data()\n",
    "    val_idx = int(len(training_data)*0.2)\n",
    "    training_subset, validation_subset = torch.utils.data.random_split(training_data, [val_idx, len(training_data)-val_idx])\n",
    "    train_dataloader = DataLoader(training_subset, batch_size=batchsize, shuffle=True)\n",
    "    val_dataloader = DataLoader(validation_subset, batch_size=batchsize, shuffle=True)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass + backprop + optimization step\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # printing stats\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "            # mini batches of 100\n",
    "            if i % 100 == 0:\n",
    "                print(f\"{epoch}, {i}, {running_loss/epoch_steps:>5f}\")\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            # validation functionality\n",
    "            val_loss = 0.0\n",
    "            val_steps = 0\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for i, data in enumerate(val_dataloader, 0):\n",
    "                with torch.no_grad():\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    loss = loss_fn(outputs, labels)\n",
    "                    val_loss += loss.numpy() \n",
    "                    val_steps += 1\n",
    "            \n",
    "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "            tune.report(loss = (val_loss/val_steps), accuracy = correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, device=\"cpu\"):\n",
    "    training_data, testing_data = load_data()\n",
    "    testloader = DataLoader(testing_data, batch_size=64, shuffle=False)\n",
    "    \n",
    "    # measure accuracy\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"l1\": tune.sample_from(lambda _: 2**np.random.randint(2, 9)),\n",
    "    \"l2\": tune.sample_from(lambda _: 2**np.random.randint(2, 9))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-01-26 13:34:59</td></tr>\n",
       "<tr><td>Running for: </td><td>00:15:43.08        </td></tr>\n",
       "<tr><td>Memory:      </td><td>12.1/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 1.0/10 CPUs, 0/0 GPUs, 0.0/6.82 GiB heap, 0.0/2.0 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  l1</th><th style=\"text-align: right;\">  l2</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   loss</th><th style=\"text-align: right;\">  accuracy</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_network_16e39_00000</td><td>RUNNING </td><td>127.0.0.1:31051</td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">   8</td><td style=\"text-align: right;\">   325</td><td style=\"text-align: right;\">         941.084</td><td style=\"text-align: right;\">2.27722</td><td style=\"text-align: right;\"> 0.0995417</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=31051)\u001b[0m /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "\u001b[2m\u001b[36m(pid=31051)\u001b[0m   Referenced from: /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/image.so\n",
      "\u001b[2m\u001b[36m(pid=31051)\u001b[0m   Expected in: /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "\u001b[2m\u001b[36m(pid=31051)\u001b[0m   warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=31051)\u001b[0m 0, 0, 2.286733\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name               </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>episodes_total  </th><th>experiment_id                   </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_network_16e39_00000</td><td style=\"text-align: right;\"> 0.0995417</td><td>2023-01-26_13-34-59</td><td>False </td><td>                </td><td>45bbd37591764a3988f40bbdf27e200d</td><td>yujians-mbp.lan</td><td style=\"text-align: right;\">                       325</td><td style=\"text-align: right;\">2.27722</td><td>127.0.0.1</td><td style=\"text-align: right;\">31051</td><td>True               </td><td style=\"text-align: right;\">             941.084</td><td style=\"text-align: right;\">           2.88751</td><td style=\"text-align: right;\">       941.084</td><td style=\"text-align: right;\"> 1674768899</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">                 325</td><td>16e39_00000</td><td style=\"text-align: right;\">   0.00209093</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(func pid=31051)\u001b[0m 0, 100, 2.283761\n",
      "\u001b[2m\u001b[36m(func pid=31051)\u001b[0m 1, 0, 2.273696\n",
      "\u001b[2m\u001b[36m(func pid=31051)\u001b[0m 1, 100, 2.266338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 13:34:57,845\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-01-26 13:34:59,958\tERROR tune.py:758 -- Trials did not complete: [train_network_16e39_00000]\n",
      "2023-01-26 13:34:59,958\tINFO tune.py:762 -- Total run time: 943.29 seconds (943.06 seconds for the tuning loop).\n",
      "2023-01-26 13:34:59,958\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    }
   ],
   "source": [
    "result = tune.run(\n",
    "    functools.partial(train_network),\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d89c39eb4a984fcf43ceca0b8c5be43979e9b8f7a2029ea8a54f4a0f5b2e7ef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
