{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "  Referenced from: /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # self.flatten = nn.Flatten()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3), # 28 x 28 --> 26 x 26 x 4\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=1), # 26 x 26 x 4 \n",
    "            nn.Flatten(), # --> (26 x 26 x 4)\n",
    "            nn.Linear(26*26*4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        # x = self.flatten(X)\n",
    "        logits = self.cnn(X)\n",
    "        return logits\n",
    "    \n",
    "    # def forward(self, X):\n",
    "    #     print(X.size())\n",
    "    #     for layer in self.cnn:\n",
    "    #         X = layer(X)\n",
    "    #         print(X.size())\n",
    "    #     return X\n",
    "\n",
    "training_data = datasets.FashionMNIST(root=\"../fashion_mnist\", train=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root=\"../fashion_mnist\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "learning_rate = 1e-3\n",
    "batch_size=64\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (cnn): Sequential(\n",
      "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Flatten(start_dim=1, end_dim=-1)\n",
      "    (4): Linear(in_features=2704, out_features=64, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 4, 26, 26])\n",
      "torch.Size([64, 4, 26, 26])\n",
      "torch.Size([64, 4, 26, 26])\n",
      "torch.Size([64, 2704])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n",
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0346e-02, -4.4125e-02,  3.0246e-02, -3.4239e-02,  1.4106e-01,\n",
       "         -5.1276e-04, -9.9090e-02,  1.0239e-01, -1.0917e-01, -5.0798e-02],\n",
       "        [ 5.4476e-03, -6.0326e-02,  5.5434e-03, -4.6536e-02,  1.4395e-01,\n",
       "          2.5580e-02, -8.0433e-02,  3.1112e-03, -3.6385e-02, -6.3081e-02],\n",
       "        [ 8.7745e-03, -6.1325e-02,  8.9097e-03, -6.6091e-02,  1.1708e-01,\n",
       "          5.6031e-02, -1.1513e-01,  4.0812e-02, -3.5788e-02, -2.9226e-03],\n",
       "        [ 3.8022e-02, -5.0692e-02,  1.8482e-03, -7.1349e-02,  1.2494e-01,\n",
       "          2.5358e-02, -1.0813e-01,  3.1888e-02, -4.4907e-02, -2.2261e-02],\n",
       "        [-1.8065e-02, -1.1054e-01,  7.3579e-03, -7.4405e-02,  1.6384e-01,\n",
       "          8.5294e-02, -1.5826e-01,  2.9774e-02, -7.2252e-02, -2.6561e-03],\n",
       "        [ 6.7308e-03, -8.2724e-02,  5.6795e-02, -4.7419e-02,  1.1176e-01,\n",
       "          5.0351e-02, -1.2336e-01, -2.8187e-02, -6.1429e-02, -1.1596e-02],\n",
       "        [ 2.8475e-02, -4.4945e-03,  5.0531e-02, -2.6639e-02,  9.7276e-02,\n",
       "         -1.0868e-02, -7.9146e-02,  3.0565e-02, -6.8072e-02, -4.5389e-02],\n",
       "        [-1.5154e-02, -1.4302e-02,  1.1188e-01, -3.2185e-02,  1.7631e-01,\n",
       "          2.8987e-02, -1.5263e-01,  1.3392e-02, -8.4169e-02, -1.1195e-01],\n",
       "        [ 4.6565e-02, -4.9820e-02,  7.6873e-02, -3.9872e-02,  9.9951e-02,\n",
       "          2.3354e-02, -9.9861e-02,  4.3703e-03, -4.1827e-02, -7.6652e-03],\n",
       "        [ 1.3511e-02, -7.1209e-02,  3.1890e-02, -3.5731e-02,  2.1146e-01,\n",
       "          1.0926e-02, -6.9534e-02,  4.4536e-02, -6.4169e-02, -5.0843e-02],\n",
       "        [ 4.1215e-03, -9.1797e-02,  1.7094e-02, -7.5821e-02,  1.5309e-01,\n",
       "          4.4703e-02, -1.2668e-01,  8.1315e-03, -4.7991e-02, -8.9372e-03],\n",
       "        [ 3.2278e-02, -3.0191e-02,  4.6570e-02, -8.4598e-02,  2.0088e-01,\n",
       "         -7.1985e-03, -9.2684e-02,  5.5250e-02, -9.6318e-02, -7.7800e-02],\n",
       "        [ 5.2241e-02, -1.5957e-02,  1.4817e-02, -6.6111e-02,  1.0822e-01,\n",
       "          1.9625e-02, -1.1428e-01,  2.6039e-02, -4.6516e-02, -1.0317e-02],\n",
       "        [ 3.6641e-02, -1.6345e-02,  7.3360e-03, -1.8032e-02,  9.4916e-02,\n",
       "          2.1176e-02, -1.2213e-01,  8.1239e-02, -6.9559e-02, -3.1644e-02],\n",
       "        [ 2.0903e-02, -1.4302e-02,  5.7128e-03, -3.6982e-02,  8.4251e-02,\n",
       "          2.0494e-02, -8.7388e-02,  3.3379e-02, -4.8878e-02, -9.1302e-03],\n",
       "        [ 3.2791e-02, -2.0324e-02,  4.1401e-02, -2.7690e-02,  1.5914e-01,\n",
       "          1.5535e-02, -1.4237e-01,  9.1616e-02, -8.6571e-02, -4.9460e-02],\n",
       "        [ 1.2779e-02, -4.7984e-02,  3.7465e-03, -4.9765e-02,  1.4847e-01,\n",
       "          4.6685e-02, -1.1091e-01,  7.1807e-02, -6.7177e-02, -2.9610e-02],\n",
       "        [-3.1474e-03, -8.7199e-02, -2.8979e-03, -7.9495e-02,  1.3550e-01,\n",
       "          4.8397e-02, -1.3021e-01, -1.2631e-02, -3.4710e-02, -1.0181e-02],\n",
       "        [ 6.2504e-03, -6.0862e-02,  6.5025e-02, -7.1049e-02,  1.7695e-01,\n",
       "          3.7601e-02, -1.1842e-01,  7.6798e-03, -6.6123e-02, -6.2655e-02],\n",
       "        [ 7.3108e-03, -5.0253e-02,  3.2181e-02, -4.9743e-02,  7.4650e-02,\n",
       "          3.0369e-02, -6.2399e-02,  1.8010e-02, -3.0735e-02,  8.7894e-03],\n",
       "        [-2.1924e-02, -8.4466e-02,  1.0572e-03, -4.2362e-02,  1.4053e-01,\n",
       "          7.5704e-02, -1.4805e-01, -2.5216e-02, -7.2019e-02, -2.5546e-02],\n",
       "        [ 2.3349e-02, -6.4973e-02,  2.4917e-02, -5.0092e-02,  1.4683e-01,\n",
       "          4.9988e-02, -1.4708e-01,  4.9246e-02, -8.2525e-02, -8.2275e-03],\n",
       "        [ 3.9738e-02, -2.8238e-02,  3.7576e-02, -4.2488e-02,  1.5378e-01,\n",
       "          4.3101e-02, -1.3507e-01,  5.2481e-02, -7.4435e-02, -6.2576e-02],\n",
       "        [-9.3069e-03, -9.9197e-02,  2.8548e-02,  1.3094e-02,  1.0019e-01,\n",
       "          1.5684e-02, -7.0325e-02,  1.4258e-02, -6.7559e-02, -2.8052e-02],\n",
       "        [-8.5701e-04, -1.7941e-02,  3.4351e-02, -8.8363e-02,  1.9698e-01,\n",
       "          4.2789e-02, -1.2643e-01,  3.9858e-02, -9.4473e-02, -5.6129e-02],\n",
       "        [ 9.6877e-03, -2.8761e-02,  5.3872e-04, -4.3651e-02,  1.4914e-01,\n",
       "          4.2792e-02, -1.4491e-01,  3.8382e-02, -3.2252e-02, -9.7618e-02],\n",
       "        [-4.9016e-03, -1.1018e-01,  4.2617e-02, -8.7835e-02,  9.9862e-02,\n",
       "          1.2665e-02, -6.4783e-02, -3.6792e-02, -6.5187e-02, -2.8985e-02],\n",
       "        [ 8.0604e-03, -7.5263e-02,  1.1671e-01, -4.4975e-02,  1.5984e-01,\n",
       "          1.7946e-02, -1.1444e-01, -2.6133e-02, -6.8957e-02, -4.4011e-02],\n",
       "        [ 1.1929e-02, -2.8074e-02,  4.4787e-02, -9.7302e-02,  1.4686e-01,\n",
       "          3.5441e-02, -1.3166e-01,  4.1255e-02, -7.7173e-02, -1.6475e-02],\n",
       "        [-3.1211e-02, -8.4197e-02,  8.6195e-02, -8.1132e-02,  1.8797e-01,\n",
       "          3.5560e-02, -1.4037e-01,  3.1311e-02, -6.5290e-02, -7.8679e-02],\n",
       "        [ 4.7299e-03, -2.6358e-02,  7.9830e-03, -6.8985e-02,  9.9809e-02,\n",
       "          2.9208e-02, -7.7721e-02,  3.2052e-02, -6.6651e-02, -4.1616e-03],\n",
       "        [ 9.8108e-03, -7.8048e-02,  2.8780e-02, -6.3872e-02,  8.5642e-02,\n",
       "          5.2316e-02, -1.0251e-01,  1.6582e-02, -4.4568e-02,  1.5119e-02],\n",
       "        [ 1.1675e-02, -1.0162e-01,  3.3892e-02, -8.1457e-02,  1.6537e-01,\n",
       "          2.2791e-02, -1.3578e-01, -2.9378e-03, -4.1294e-02, -2.1487e-02],\n",
       "        [ 4.0603e-02, -3.7724e-02,  2.1931e-02, -5.3814e-02,  7.3082e-02,\n",
       "          1.1479e-02, -7.8449e-02,  4.4155e-02, -3.4378e-02,  9.8523e-03],\n",
       "        [ 1.9496e-02, -4.6513e-02,  3.4780e-03, -8.0060e-02,  8.9036e-02,\n",
       "          1.8406e-03, -5.3171e-02,  1.9704e-02, -2.7013e-02,  1.4029e-02],\n",
       "        [ 4.6061e-02, -9.1459e-02,  4.8554e-02, -6.2849e-02,  1.1546e-01,\n",
       "          1.4280e-02, -1.0914e-01,  3.8979e-02, -6.1795e-02, -8.6351e-03],\n",
       "        [ 6.3616e-02, -6.5055e-02,  9.2229e-03, -3.0876e-02,  1.6624e-01,\n",
       "          2.4534e-02, -1.1277e-01,  2.0716e-02, -4.4560e-02, -3.3626e-02],\n",
       "        [ 9.2794e-03, -7.2603e-02,  4.1321e-02, -7.5117e-02,  1.0204e-01,\n",
       "          2.4300e-02, -8.9925e-02, -1.9937e-02, -3.1738e-02, -2.3246e-02],\n",
       "        [ 2.9228e-02, -3.8914e-02,  1.9434e-02, -2.5323e-02,  1.1756e-01,\n",
       "          2.9527e-02, -1.5153e-01,  5.4888e-02, -6.7495e-02, -3.0295e-02],\n",
       "        [-4.3383e-02, -6.8989e-02,  5.2837e-02, -9.6387e-02,  2.0631e-01,\n",
       "          5.0023e-02, -1.2373e-01, -7.7200e-03, -8.0744e-02, -3.9957e-02],\n",
       "        [-3.3450e-02, -5.3553e-02,  3.5108e-02, -6.9552e-02,  1.5790e-01,\n",
       "          9.5870e-02, -1.3738e-01, -4.2871e-02, -9.0621e-02, -2.9712e-02],\n",
       "        [ 1.6864e-02,  5.2312e-03,  2.8704e-02, -4.8900e-03,  1.2326e-01,\n",
       "          1.7509e-02, -4.7127e-02,  2.9252e-02, -6.0030e-02, -5.3183e-02],\n",
       "        [ 3.5671e-02, -1.0560e-02,  3.6343e-03, -4.7523e-02,  1.4249e-01,\n",
       "          1.6470e-02, -1.4303e-01,  8.0004e-02, -6.8315e-02, -2.9254e-02],\n",
       "        [ 8.5548e-02, -4.6259e-02,  7.3504e-02, -2.9295e-02,  7.9169e-02,\n",
       "         -3.0715e-02, -1.3330e-01,  2.9451e-02, -3.6247e-02, -3.7140e-02],\n",
       "        [-2.4289e-02, -8.5938e-02,  1.1187e-01, -3.7182e-02,  1.8436e-01,\n",
       "          2.5877e-02, -1.2233e-01,  6.0341e-02, -3.3519e-02, -7.4656e-02],\n",
       "        [ 4.9661e-03, -3.3386e-02,  7.0287e-02, -7.7167e-02,  1.6403e-01,\n",
       "          4.6510e-02, -1.1326e-01, -5.3138e-04, -7.1573e-02, -3.2429e-02],\n",
       "        [ 3.7997e-02,  5.0001e-05,  3.0291e-02, -2.0495e-02,  1.0232e-01,\n",
       "          1.3659e-02, -8.9157e-02,  2.9681e-02, -7.9044e-02, -3.5908e-02],\n",
       "        [-8.4716e-03, -7.6930e-02,  8.8313e-03, -3.9906e-02,  1.4968e-01,\n",
       "          6.7961e-02, -1.3976e-01,  2.8277e-03, -7.5698e-02, -3.3970e-02],\n",
       "        [-3.2981e-03, -7.8563e-02,  2.6539e-02, -4.9770e-02,  9.8335e-02,\n",
       "          1.5870e-02, -6.3709e-02, -2.8658e-02, -3.7106e-02, -7.2670e-03],\n",
       "        [ 7.7385e-03, -4.5763e-02,  3.2907e-03, -6.3622e-02,  1.4479e-01,\n",
       "          3.5569e-02, -1.2865e-01,  2.7722e-02, -6.8903e-02, -4.8054e-02],\n",
       "        [-3.3250e-02, -8.9593e-02,  2.6580e-02, -6.8116e-02,  1.3479e-01,\n",
       "          5.6422e-02, -1.3834e-01, -8.9103e-03, -3.5762e-02, -3.8388e-02],\n",
       "        [ 1.5682e-02, -7.1673e-02,  6.6580e-03, -4.0763e-02,  9.5513e-02,\n",
       "          4.9222e-02, -1.4259e-01, -1.9597e-03, -6.1168e-02, -2.7315e-02],\n",
       "        [ 3.5767e-02, -9.4207e-03,  2.1149e-02, -3.1459e-02,  9.5052e-02,\n",
       "         -2.2362e-03, -1.0328e-01,  6.1567e-02, -4.4412e-02, -2.1076e-02],\n",
       "        [-2.3205e-02, -6.7060e-02,  7.9589e-02, -7.8729e-02,  2.0491e-01,\n",
       "          6.6052e-02, -1.4792e-01, -2.2778e-02, -7.1213e-02, -6.9874e-02],\n",
       "        [ 1.7163e-02, -3.3448e-02,  2.0856e-02, -6.5873e-02,  1.0108e-01,\n",
       "          2.3357e-02, -8.5729e-02,  2.5417e-02, -6.0069e-02, -2.8185e-03],\n",
       "        [ 2.4534e-02, -7.6527e-02,  8.9287e-03, -7.1290e-02,  1.3533e-01,\n",
       "          2.8154e-02, -9.4465e-02, -1.9332e-03, -4.1667e-02, -1.9860e-02],\n",
       "        [-2.7776e-02, -4.6306e-02,  6.7768e-03, -4.1532e-02,  1.0680e-01,\n",
       "          7.7503e-02, -9.1265e-02, -9.5808e-03, -4.9595e-02, -7.0620e-03],\n",
       "        [ 1.9009e-02, -8.4013e-02,  1.8632e-02, -5.5769e-02,  1.1418e-01,\n",
       "          2.4038e-02, -1.0650e-01,  2.9001e-02, -1.0959e-02, -1.9489e-02],\n",
       "        [-3.7329e-02, -1.0063e-01,  2.2661e-02, -5.4957e-02,  1.3769e-01,\n",
       "          7.3153e-02, -1.5386e-01,  3.7554e-03, -4.2856e-02, -3.3959e-02],\n",
       "        [-1.2454e-02, -7.8452e-02,  5.0028e-02, -5.3599e-02,  7.0095e-02,\n",
       "          2.4328e-02, -1.0192e-01,  1.5877e-02, -4.7815e-02, -2.3684e-02],\n",
       "        [ 4.5664e-03, -9.2746e-02,  6.1436e-02, -4.3042e-02,  1.5400e-01,\n",
       "          3.1434e-02, -4.5199e-02,  1.1969e-02, -7.6491e-02,  4.9415e-03],\n",
       "        [ 2.5557e-02, -2.7852e-02,  2.1764e-02, -9.7302e-02,  1.1877e-01,\n",
       "          5.9021e-03, -7.9020e-02,  5.3453e-02, -5.1079e-02, -1.6029e-02],\n",
       "        [ 7.4725e-02,  4.4992e-03,  5.8473e-02, -4.1781e-02,  7.8216e-02,\n",
       "          6.0195e-03, -8.6027e-02,  2.6007e-02, -5.6881e-02,  6.3108e-03],\n",
       "        [ 2.4987e-02, -5.4042e-02,  2.1512e-02, -6.4902e-02,  9.1573e-02,\n",
       "          2.4106e-02, -9.4082e-02,  4.7218e-02, -4.7740e-02,  6.5017e-03]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = torch.stack([training_data[x][0] for x in range(0, 64)])\n",
    "model(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # predictions\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Current loss: {loss:>7f}, [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_loop(epoch_list, accuracy_list, epochs, _optimizer=optimizer):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n\")\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer = _optimizer)\n",
    "        accuracy = test_loop(test_dataloader, model, loss_fn, optimizer = _optimizer)\n",
    "        epoch_list.append(t)\n",
    "        accuracy_list.append(accuracy)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Current loss: 2.306516, [    0/60000]\n",
      "Current loss: 2.233973, [ 6400/60000]\n",
      "Current loss: 2.146708, [12800/60000]\n",
      "Current loss: 2.100178, [19200/60000]\n",
      "Current loss: 2.010174, [25600/60000]\n",
      "Current loss: 1.883833, [32000/60000]\n",
      "Current loss: 1.832211, [38400/60000]\n",
      "Current loss: 1.645493, [44800/60000]\n",
      "Current loss: 1.528988, [51200/60000]\n",
      "Current loss: 1.352238, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 63.4%, Avg loss: 1.339488\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "Current loss: 1.415871, [    0/60000]\n",
      "Current loss: 1.309743, [ 6400/60000]\n",
      "Current loss: 1.105446, [12800/60000]\n",
      "Current loss: 1.144978, [19200/60000]\n",
      "Current loss: 0.997873, [25600/60000]\n",
      "Current loss: 0.991498, [32000/60000]\n",
      "Current loss: 0.996030, [38400/60000]\n",
      "Current loss: 0.934652, [44800/60000]\n",
      "Current loss: 0.941338, [51200/60000]\n",
      "Current loss: 0.876024, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 68.6%, Avg loss: 0.877375\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "Current loss: 0.909917, [    0/60000]\n",
      "Current loss: 0.934800, [ 6400/60000]\n",
      "Current loss: 0.711993, [12800/60000]\n",
      "Current loss: 0.899123, [19200/60000]\n",
      "Current loss: 0.807398, [25600/60000]\n",
      "Current loss: 0.787197, [32000/60000]\n",
      "Current loss: 0.831795, [38400/60000]\n",
      "Current loss: 0.786965, [44800/60000]\n",
      "Current loss: 0.801993, [51200/60000]\n",
      "Current loss: 0.774897, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 72.8%, Avg loss: 0.759341\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "Current loss: 0.742474, [    0/60000]\n",
      "Current loss: 0.816363, [ 6400/60000]\n",
      "Current loss: 0.577352, [12800/60000]\n",
      "Current loss: 0.813307, [19200/60000]\n",
      "Current loss: 0.741202, [25600/60000]\n",
      "Current loss: 0.709471, [32000/60000]\n",
      "Current loss: 0.758174, [38400/60000]\n",
      "Current loss: 0.729501, [44800/60000]\n",
      "Current loss: 0.738085, [51200/60000]\n",
      "Current loss: 0.715261, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 75.3%, Avg loss: 0.698073\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "Current loss: 0.656649, [    0/60000]\n",
      "Current loss: 0.745494, [ 6400/60000]\n",
      "Current loss: 0.507475, [12800/60000]\n",
      "Current loss: 0.762208, [19200/60000]\n",
      "Current loss: 0.693813, [25600/60000]\n",
      "Current loss: 0.663474, [32000/60000]\n",
      "Current loss: 0.707328, [38400/60000]\n",
      "Current loss: 0.698442, [44800/60000]\n",
      "Current loss: 0.704771, [51200/60000]\n",
      "Current loss: 0.670187, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 77.0%, Avg loss: 0.657366\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "Current loss: 0.604548, [    0/60000]\n",
      "Current loss: 0.694315, [ 6400/60000]\n",
      "Current loss: 0.462688, [12800/60000]\n",
      "Current loss: 0.727250, [19200/60000]\n",
      "Current loss: 0.659997, [25600/60000]\n",
      "Current loss: 0.632243, [32000/60000]\n",
      "Current loss: 0.668491, [38400/60000]\n",
      "Current loss: 0.678941, [44800/60000]\n",
      "Current loss: 0.687119, [51200/60000]\n",
      "Current loss: 0.632851, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 78.0%, Avg loss: 0.627761\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "Current loss: 0.569665, [    0/60000]\n",
      "Current loss: 0.655959, [ 6400/60000]\n",
      "Current loss: 0.430596, [12800/60000]\n",
      "Current loss: 0.701199, [19200/60000]\n",
      "Current loss: 0.635784, [25600/60000]\n",
      "Current loss: 0.607794, [32000/60000]\n",
      "Current loss: 0.638201, [38400/60000]\n",
      "Current loss: 0.666704, [44800/60000]\n",
      "Current loss: 0.678221, [51200/60000]\n",
      "Current loss: 0.601399, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 78.8%, Avg loss: 0.604977\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "Current loss: 0.544257, [    0/60000]\n",
      "Current loss: 0.627043, [ 6400/60000]\n",
      "Current loss: 0.405988, [12800/60000]\n",
      "Current loss: 0.679557, [19200/60000]\n",
      "Current loss: 0.616202, [25600/60000]\n",
      "Current loss: 0.587857, [32000/60000]\n",
      "Current loss: 0.614135, [38400/60000]\n",
      "Current loss: 0.659317, [44800/60000]\n",
      "Current loss: 0.673316, [51200/60000]\n",
      "Current loss: 0.574574, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 79.4%, Avg loss: 0.586650\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "Current loss: 0.523712, [    0/60000]\n",
      "Current loss: 0.604842, [ 6400/60000]\n",
      "Current loss: 0.386123, [12800/60000]\n",
      "Current loss: 0.661315, [19200/60000]\n",
      "Current loss: 0.599030, [25600/60000]\n",
      "Current loss: 0.569938, [32000/60000]\n",
      "Current loss: 0.595360, [38400/60000]\n",
      "Current loss: 0.654993, [44800/60000]\n",
      "Current loss: 0.670793, [51200/60000]\n",
      "Current loss: 0.551715, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 80.1%, Avg loss: 0.571579\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "Current loss: 0.505394, [    0/60000]\n",
      "Current loss: 0.585267, [ 6400/60000]\n",
      "Current loss: 0.370047, [12800/60000]\n",
      "Current loss: 0.644160, [19200/60000]\n",
      "Current loss: 0.582760, [25600/60000]\n",
      "Current loss: 0.552181, [32000/60000]\n",
      "Current loss: 0.579336, [38400/60000]\n",
      "Current loss: 0.651776, [44800/60000]\n",
      "Current loss: 0.668725, [51200/60000]\n",
      "Current loss: 0.532170, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 80.5%, Avg loss: 0.558844\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "Current loss: 0.488910, [    0/60000]\n",
      "Current loss: 0.568170, [ 6400/60000]\n",
      "Current loss: 0.356210, [12800/60000]\n",
      "Current loss: 0.628977, [19200/60000]\n",
      "Current loss: 0.568703, [25600/60000]\n",
      "Current loss: 0.535735, [32000/60000]\n",
      "Current loss: 0.565494, [38400/60000]\n",
      "Current loss: 0.649307, [44800/60000]\n",
      "Current loss: 0.666576, [51200/60000]\n",
      "Current loss: 0.515037, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 81.0%, Avg loss: 0.547714\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "Current loss: 0.473964, [    0/60000]\n",
      "Current loss: 0.553811, [ 6400/60000]\n",
      "Current loss: 0.343685, [12800/60000]\n",
      "Current loss: 0.613592, [19200/60000]\n",
      "Current loss: 0.555180, [25600/60000]\n",
      "Current loss: 0.520252, [32000/60000]\n",
      "Current loss: 0.553525, [38400/60000]\n",
      "Current loss: 0.646522, [44800/60000]\n",
      "Current loss: 0.663802, [51200/60000]\n",
      "Current loss: 0.500325, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 81.5%, Avg loss: 0.538040\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "Current loss: 0.460602, [    0/60000]\n",
      "Current loss: 0.540860, [ 6400/60000]\n",
      "Current loss: 0.331828, [12800/60000]\n",
      "Current loss: 0.600634, [19200/60000]\n",
      "Current loss: 0.542636, [25600/60000]\n",
      "Current loss: 0.505945, [32000/60000]\n",
      "Current loss: 0.542607, [38400/60000]\n",
      "Current loss: 0.644144, [44800/60000]\n",
      "Current loss: 0.661711, [51200/60000]\n",
      "Current loss: 0.488756, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 81.6%, Avg loss: 0.529406\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "Current loss: 0.450842, [    0/60000]\n",
      "Current loss: 0.529886, [ 6400/60000]\n",
      "Current loss: 0.322389, [12800/60000]\n",
      "Current loss: 0.588355, [19200/60000]\n",
      "Current loss: 0.530443, [25600/60000]\n",
      "Current loss: 0.492429, [32000/60000]\n",
      "Current loss: 0.533846, [38400/60000]\n",
      "Current loss: 0.640770, [44800/60000]\n",
      "Current loss: 0.658798, [51200/60000]\n",
      "Current loss: 0.478191, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 81.8%, Avg loss: 0.521607\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "Current loss: 0.441579, [    0/60000]\n",
      "Current loss: 0.519823, [ 6400/60000]\n",
      "Current loss: 0.314207, [12800/60000]\n",
      "Current loss: 0.576149, [19200/60000]\n",
      "Current loss: 0.520483, [25600/60000]\n",
      "Current loss: 0.479786, [32000/60000]\n",
      "Current loss: 0.525671, [38400/60000]\n",
      "Current loss: 0.637512, [44800/60000]\n",
      "Current loss: 0.655931, [51200/60000]\n",
      "Current loss: 0.467836, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.1%, Avg loss: 0.514714\n",
      "\n",
      "Epoch 16\n",
      "\n",
      "Current loss: 0.432722, [    0/60000]\n",
      "Current loss: 0.510343, [ 6400/60000]\n",
      "Current loss: 0.306885, [12800/60000]\n",
      "Current loss: 0.565824, [19200/60000]\n",
      "Current loss: 0.510255, [25600/60000]\n",
      "Current loss: 0.467397, [32000/60000]\n",
      "Current loss: 0.518971, [38400/60000]\n",
      "Current loss: 0.634348, [44800/60000]\n",
      "Current loss: 0.651556, [51200/60000]\n",
      "Current loss: 0.458723, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.2%, Avg loss: 0.508473\n",
      "\n",
      "Epoch 17\n",
      "\n",
      "Current loss: 0.423719, [    0/60000]\n",
      "Current loss: 0.501638, [ 6400/60000]\n",
      "Current loss: 0.299497, [12800/60000]\n",
      "Current loss: 0.556618, [19200/60000]\n",
      "Current loss: 0.499497, [25600/60000]\n",
      "Current loss: 0.457225, [32000/60000]\n",
      "Current loss: 0.512525, [38400/60000]\n",
      "Current loss: 0.631211, [44800/60000]\n",
      "Current loss: 0.648720, [51200/60000]\n",
      "Current loss: 0.452227, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.3%, Avg loss: 0.502731\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "Current loss: 0.415115, [    0/60000]\n",
      "Current loss: 0.492710, [ 6400/60000]\n",
      "Current loss: 0.293799, [12800/60000]\n",
      "Current loss: 0.547932, [19200/60000]\n",
      "Current loss: 0.489549, [25600/60000]\n",
      "Current loss: 0.447973, [32000/60000]\n",
      "Current loss: 0.507373, [38400/60000]\n",
      "Current loss: 0.628090, [44800/60000]\n",
      "Current loss: 0.644821, [51200/60000]\n",
      "Current loss: 0.445924, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.5%, Avg loss: 0.497660\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "Current loss: 0.405832, [    0/60000]\n",
      "Current loss: 0.485224, [ 6400/60000]\n",
      "Current loss: 0.288628, [12800/60000]\n",
      "Current loss: 0.540122, [19200/60000]\n",
      "Current loss: 0.478015, [25600/60000]\n",
      "Current loss: 0.440456, [32000/60000]\n",
      "Current loss: 0.502280, [38400/60000]\n",
      "Current loss: 0.625384, [44800/60000]\n",
      "Current loss: 0.639963, [51200/60000]\n",
      "Current loss: 0.441399, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.6%, Avg loss: 0.492748\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "Current loss: 0.398133, [    0/60000]\n",
      "Current loss: 0.478150, [ 6400/60000]\n",
      "Current loss: 0.284220, [12800/60000]\n",
      "Current loss: 0.533807, [19200/60000]\n",
      "Current loss: 0.467979, [25600/60000]\n",
      "Current loss: 0.432546, [32000/60000]\n",
      "Current loss: 0.497013, [38400/60000]\n",
      "Current loss: 0.621951, [44800/60000]\n",
      "Current loss: 0.636343, [51200/60000]\n",
      "Current loss: 0.437640, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.8%, Avg loss: 0.488384\n",
      "\n",
      "Epoch 21\n",
      "\n",
      "Current loss: 0.391299, [    0/60000]\n",
      "Current loss: 0.472141, [ 6400/60000]\n",
      "Current loss: 0.280093, [12800/60000]\n",
      "Current loss: 0.526389, [19200/60000]\n",
      "Current loss: 0.460000, [25600/60000]\n",
      "Current loss: 0.426118, [32000/60000]\n",
      "Current loss: 0.492511, [38400/60000]\n",
      "Current loss: 0.616685, [44800/60000]\n",
      "Current loss: 0.633028, [51200/60000]\n",
      "Current loss: 0.433420, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.9%, Avg loss: 0.484080\n",
      "\n",
      "Epoch 22\n",
      "\n",
      "Current loss: 0.384797, [    0/60000]\n",
      "Current loss: 0.466587, [ 6400/60000]\n",
      "Current loss: 0.275740, [12800/60000]\n",
      "Current loss: 0.520778, [19200/60000]\n",
      "Current loss: 0.450832, [25600/60000]\n",
      "Current loss: 0.419791, [32000/60000]\n",
      "Current loss: 0.487486, [38400/60000]\n",
      "Current loss: 0.611450, [44800/60000]\n",
      "Current loss: 0.630175, [51200/60000]\n",
      "Current loss: 0.429311, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 82.9%, Avg loss: 0.480161\n",
      "\n",
      "Epoch 23\n",
      "\n",
      "Current loss: 0.378801, [    0/60000]\n",
      "Current loss: 0.461664, [ 6400/60000]\n",
      "Current loss: 0.272726, [12800/60000]\n",
      "Current loss: 0.514787, [19200/60000]\n",
      "Current loss: 0.443110, [25600/60000]\n",
      "Current loss: 0.414226, [32000/60000]\n",
      "Current loss: 0.482806, [38400/60000]\n",
      "Current loss: 0.606297, [44800/60000]\n",
      "Current loss: 0.626081, [51200/60000]\n",
      "Current loss: 0.425466, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.2%, Avg loss: 0.476425\n",
      "\n",
      "Epoch 24\n",
      "\n",
      "Current loss: 0.372961, [    0/60000]\n",
      "Current loss: 0.456071, [ 6400/60000]\n",
      "Current loss: 0.269248, [12800/60000]\n",
      "Current loss: 0.508837, [19200/60000]\n",
      "Current loss: 0.436007, [25600/60000]\n",
      "Current loss: 0.408053, [32000/60000]\n",
      "Current loss: 0.478515, [38400/60000]\n",
      "Current loss: 0.601869, [44800/60000]\n",
      "Current loss: 0.622111, [51200/60000]\n",
      "Current loss: 0.422715, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.3%, Avg loss: 0.473011\n",
      "\n",
      "Epoch 25\n",
      "\n",
      "Current loss: 0.366445, [    0/60000]\n",
      "Current loss: 0.451126, [ 6400/60000]\n",
      "Current loss: 0.266382, [12800/60000]\n",
      "Current loss: 0.503709, [19200/60000]\n",
      "Current loss: 0.428637, [25600/60000]\n",
      "Current loss: 0.402547, [32000/60000]\n",
      "Current loss: 0.474207, [38400/60000]\n",
      "Current loss: 0.596928, [44800/60000]\n",
      "Current loss: 0.618541, [51200/60000]\n",
      "Current loss: 0.419645, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.4%, Avg loss: 0.469812\n",
      "\n",
      "Epoch 26\n",
      "\n",
      "Current loss: 0.361337, [    0/60000]\n",
      "Current loss: 0.446372, [ 6400/60000]\n",
      "Current loss: 0.263182, [12800/60000]\n",
      "Current loss: 0.499137, [19200/60000]\n",
      "Current loss: 0.421926, [25600/60000]\n",
      "Current loss: 0.398950, [32000/60000]\n",
      "Current loss: 0.469549, [38400/60000]\n",
      "Current loss: 0.592328, [44800/60000]\n",
      "Current loss: 0.615247, [51200/60000]\n",
      "Current loss: 0.416998, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.5%, Avg loss: 0.466549\n",
      "\n",
      "Epoch 27\n",
      "\n",
      "Current loss: 0.357242, [    0/60000]\n",
      "Current loss: 0.442508, [ 6400/60000]\n",
      "Current loss: 0.260194, [12800/60000]\n",
      "Current loss: 0.494930, [19200/60000]\n",
      "Current loss: 0.416353, [25600/60000]\n",
      "Current loss: 0.394959, [32000/60000]\n",
      "Current loss: 0.465576, [38400/60000]\n",
      "Current loss: 0.588048, [44800/60000]\n",
      "Current loss: 0.612164, [51200/60000]\n",
      "Current loss: 0.414812, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.6%, Avg loss: 0.463719\n",
      "\n",
      "Epoch 28\n",
      "\n",
      "Current loss: 0.352749, [    0/60000]\n",
      "Current loss: 0.437428, [ 6400/60000]\n",
      "Current loss: 0.258660, [12800/60000]\n",
      "Current loss: 0.490225, [19200/60000]\n",
      "Current loss: 0.413065, [25600/60000]\n",
      "Current loss: 0.390924, [32000/60000]\n",
      "Current loss: 0.461578, [38400/60000]\n",
      "Current loss: 0.583151, [44800/60000]\n",
      "Current loss: 0.608570, [51200/60000]\n",
      "Current loss: 0.413166, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.7%, Avg loss: 0.460901\n",
      "\n",
      "Epoch 29\n",
      "\n",
      "Current loss: 0.349272, [    0/60000]\n",
      "Current loss: 0.433956, [ 6400/60000]\n",
      "Current loss: 0.256946, [12800/60000]\n",
      "Current loss: 0.485833, [19200/60000]\n",
      "Current loss: 0.407212, [25600/60000]\n",
      "Current loss: 0.386814, [32000/60000]\n",
      "Current loss: 0.457643, [38400/60000]\n",
      "Current loss: 0.579004, [44800/60000]\n",
      "Current loss: 0.604608, [51200/60000]\n",
      "Current loss: 0.411455, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.8%, Avg loss: 0.458122\n",
      "\n",
      "Epoch 30\n",
      "\n",
      "Current loss: 0.345290, [    0/60000]\n",
      "Current loss: 0.430494, [ 6400/60000]\n",
      "Current loss: 0.254773, [12800/60000]\n",
      "Current loss: 0.482147, [19200/60000]\n",
      "Current loss: 0.401434, [25600/60000]\n",
      "Current loss: 0.384170, [32000/60000]\n",
      "Current loss: 0.454164, [38400/60000]\n",
      "Current loss: 0.575085, [44800/60000]\n",
      "Current loss: 0.600791, [51200/60000]\n",
      "Current loss: 0.409681, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 83.9%, Avg loss: 0.455550\n",
      "\n",
      "Epoch 31\n",
      "\n",
      "Current loss: 0.341816, [    0/60000]\n",
      "Current loss: 0.427625, [ 6400/60000]\n",
      "Current loss: 0.253710, [12800/60000]\n",
      "Current loss: 0.478399, [19200/60000]\n",
      "Current loss: 0.397164, [25600/60000]\n",
      "Current loss: 0.380275, [32000/60000]\n",
      "Current loss: 0.450949, [38400/60000]\n",
      "Current loss: 0.570534, [44800/60000]\n",
      "Current loss: 0.597047, [51200/60000]\n",
      "Current loss: 0.408387, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.0%, Avg loss: 0.453060\n",
      "\n",
      "Epoch 32\n",
      "\n",
      "Current loss: 0.339651, [    0/60000]\n",
      "Current loss: 0.424647, [ 6400/60000]\n",
      "Current loss: 0.252093, [12800/60000]\n",
      "Current loss: 0.475184, [19200/60000]\n",
      "Current loss: 0.393345, [25600/60000]\n",
      "Current loss: 0.376782, [32000/60000]\n",
      "Current loss: 0.448689, [38400/60000]\n",
      "Current loss: 0.566761, [44800/60000]\n",
      "Current loss: 0.593865, [51200/60000]\n",
      "Current loss: 0.407944, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.1%, Avg loss: 0.450574\n",
      "\n",
      "Epoch 33\n",
      "\n",
      "Current loss: 0.338314, [    0/60000]\n",
      "Current loss: 0.422702, [ 6400/60000]\n",
      "Current loss: 0.250731, [12800/60000]\n",
      "Current loss: 0.472348, [19200/60000]\n",
      "Current loss: 0.389190, [25600/60000]\n",
      "Current loss: 0.373165, [32000/60000]\n",
      "Current loss: 0.444170, [38400/60000]\n",
      "Current loss: 0.563215, [44800/60000]\n",
      "Current loss: 0.588879, [51200/60000]\n",
      "Current loss: 0.407275, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.2%, Avg loss: 0.448290\n",
      "\n",
      "Epoch 34\n",
      "\n",
      "Current loss: 0.336539, [    0/60000]\n",
      "Current loss: 0.419584, [ 6400/60000]\n",
      "Current loss: 0.249104, [12800/60000]\n",
      "Current loss: 0.469453, [19200/60000]\n",
      "Current loss: 0.385585, [25600/60000]\n",
      "Current loss: 0.370026, [32000/60000]\n",
      "Current loss: 0.440001, [38400/60000]\n",
      "Current loss: 0.559956, [44800/60000]\n",
      "Current loss: 0.586010, [51200/60000]\n",
      "Current loss: 0.405745, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.3%, Avg loss: 0.446160\n",
      "\n",
      "Epoch 35\n",
      "\n",
      "Current loss: 0.334192, [    0/60000]\n",
      "Current loss: 0.416565, [ 6400/60000]\n",
      "Current loss: 0.247311, [12800/60000]\n",
      "Current loss: 0.467900, [19200/60000]\n",
      "Current loss: 0.381506, [25600/60000]\n",
      "Current loss: 0.367690, [32000/60000]\n",
      "Current loss: 0.437148, [38400/60000]\n",
      "Current loss: 0.556856, [44800/60000]\n",
      "Current loss: 0.582182, [51200/60000]\n",
      "Current loss: 0.404694, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.4%, Avg loss: 0.444065\n",
      "\n",
      "Epoch 36\n",
      "\n",
      "Current loss: 0.332768, [    0/60000]\n",
      "Current loss: 0.413638, [ 6400/60000]\n",
      "Current loss: 0.245719, [12800/60000]\n",
      "Current loss: 0.466219, [19200/60000]\n",
      "Current loss: 0.378187, [25600/60000]\n",
      "Current loss: 0.365368, [32000/60000]\n",
      "Current loss: 0.433538, [38400/60000]\n",
      "Current loss: 0.552616, [44800/60000]\n",
      "Current loss: 0.578634, [51200/60000]\n",
      "Current loss: 0.403750, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.5%, Avg loss: 0.442011\n",
      "\n",
      "Epoch 37\n",
      "\n",
      "Current loss: 0.330604, [    0/60000]\n",
      "Current loss: 0.411175, [ 6400/60000]\n",
      "Current loss: 0.244987, [12800/60000]\n",
      "Current loss: 0.463997, [19200/60000]\n",
      "Current loss: 0.373901, [25600/60000]\n",
      "Current loss: 0.363362, [32000/60000]\n",
      "Current loss: 0.431097, [38400/60000]\n",
      "Current loss: 0.550028, [44800/60000]\n",
      "Current loss: 0.572196, [51200/60000]\n",
      "Current loss: 0.403519, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.6%, Avg loss: 0.440251\n",
      "\n",
      "Epoch 38\n",
      "\n",
      "Current loss: 0.329283, [    0/60000]\n",
      "Current loss: 0.409014, [ 6400/60000]\n",
      "Current loss: 0.243633, [12800/60000]\n",
      "Current loss: 0.461729, [19200/60000]\n",
      "Current loss: 0.371028, [25600/60000]\n",
      "Current loss: 0.360515, [32000/60000]\n",
      "Current loss: 0.427962, [38400/60000]\n",
      "Current loss: 0.547062, [44800/60000]\n",
      "Current loss: 0.567774, [51200/60000]\n",
      "Current loss: 0.401784, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.6%, Avg loss: 0.438324\n",
      "\n",
      "Epoch 39\n",
      "\n",
      "Current loss: 0.327862, [    0/60000]\n",
      "Current loss: 0.407371, [ 6400/60000]\n",
      "Current loss: 0.242343, [12800/60000]\n",
      "Current loss: 0.460606, [19200/60000]\n",
      "Current loss: 0.368876, [25600/60000]\n",
      "Current loss: 0.358730, [32000/60000]\n",
      "Current loss: 0.425310, [38400/60000]\n",
      "Current loss: 0.544597, [44800/60000]\n",
      "Current loss: 0.564952, [51200/60000]\n",
      "Current loss: 0.401295, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.6%, Avg loss: 0.436926\n",
      "\n",
      "Epoch 40\n",
      "\n",
      "Current loss: 0.326946, [    0/60000]\n",
      "Current loss: 0.406174, [ 6400/60000]\n",
      "Current loss: 0.241479, [12800/60000]\n",
      "Current loss: 0.458956, [19200/60000]\n",
      "Current loss: 0.366266, [25600/60000]\n",
      "Current loss: 0.356722, [32000/60000]\n",
      "Current loss: 0.422746, [38400/60000]\n",
      "Current loss: 0.542020, [44800/60000]\n",
      "Current loss: 0.561588, [51200/60000]\n",
      "Current loss: 0.400416, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 84.8%, Avg loss: 0.434934\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "plot_x = [] # epoch\n",
    "plot_y = [] # accuracy\n",
    "optimize_loop(plot_x, plot_y, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w/ maxpool k=3: 2048x8 --> 2^14\n",
    "\n",
    "w/ maxpool k=2: 3328x13\n",
    "\n",
    "w/o maxpool: 6656x26 (26 x 4 x 64)\n",
    "\n",
    "w/ Flatten + Maxpool Kernel Size 2: turns into 64x(26x26)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(plot_x, plot_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 12.08,\n",
       " 55.81,\n",
       " 66.0,\n",
       " 71.83,\n",
       " 74.55000000000001,\n",
       " 76.31,\n",
       " 77.73,\n",
       " 78.49000000000001,\n",
       " 79.03,\n",
       " 79.45,\n",
       " 80.13,\n",
       " 80.54,\n",
       " 80.88,\n",
       " 81.14,\n",
       " 81.43,\n",
       " 81.67999999999999,\n",
       " 81.94,\n",
       " 82.0,\n",
       " 82.07,\n",
       " 82.21000000000001,\n",
       " 82.36,\n",
       " 82.49,\n",
       " 82.62,\n",
       " 82.71,\n",
       " 82.91,\n",
       " 83.07,\n",
       " 83.21,\n",
       " 83.32000000000001,\n",
       " 83.41,\n",
       " 83.58,\n",
       " 83.72,\n",
       " 83.83,\n",
       " 83.89999999999999,\n",
       " 84.0,\n",
       " 84.02,\n",
       " 84.0,\n",
       " 84.03,\n",
       " 84.11,\n",
       " 84.14,\n",
       " 84.27,\n",
       " 84.35000000000001]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (main, Jan 25 2022, 07:39:16) [Clang 13.0.0 (clang-1300.0.27.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d89c39eb4a984fcf43ceca0b8c5be43979e9b8f7a2029ea8a54f4a0f5b2e7ef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
