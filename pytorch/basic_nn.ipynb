{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.3-cp310-cp310-macosx_11_0_arm64.whl (7.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib) (21.3)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.7-cp310-cp310-macosx_11_0_arm64.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.7/229.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-macosx_11_0_arm64.whl (63 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.0.7 cycler-0.11.0 fonttools-4.38.0 kiwisolver-1.4.4 matplotlib-3.6.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefINS2_6SymIntEEENS2_8optionalINS2_10ScalarTypeEEENS6_INS2_6LayoutEEENS6_INS2_6DeviceEEENS6_IbEENS6_INS2_12MemoryFormatEEE\n",
      "  Referenced from: /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in: /Users/yujian/.pyenv/versions/3.10.1/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.flatten(X)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "training_data = datasets.FashionMNIST(root=\"fashion_mnist\", train=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root=\"fashion_mnist\", train=False, transform=transforms.ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size=64\n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # predictions\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch%100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Current loss: {loss:>7f}, [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error:\\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\\n\")\n",
    "    return 100*correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_x = [] # epoch\n",
    "plot_y = [] # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_loop(epoch_list, accuracy_list, epochs):\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t+1}\\n\")\n",
    "        train_loop(train_dataloader, new_model, loss_fn, optimizer = torch.optim.SGD(new_model.parameters(), lr=learning_rate))\n",
    "        test_loop(test_dataloader, new_model, loss_fn, optimizer = torch.optim.SGD(new_model.parameters(), lr=learning_rate))\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "\n",
      "Current loss: 2.307214, [    0/60000]\n",
      "Current loss: 2.300723, [ 6400/60000]\n",
      "Current loss: 2.281263, [12800/60000]\n",
      "Current loss: 2.274702, [19200/60000]\n",
      "Current loss: 2.265342, [25600/60000]\n",
      "Current loss: 2.233254, [32000/60000]\n",
      "Current loss: 2.243182, [38400/60000]\n",
      "Current loss: 2.213175, [44800/60000]\n",
      "Current loss: 2.205196, [51200/60000]\n",
      "Current loss: 2.186853, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 40.6%, Avg loss: 2.179526\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "Current loss: 2.187114, [    0/60000]\n",
      "Current loss: 2.184573, [ 6400/60000]\n",
      "Current loss: 2.128052, [12800/60000]\n",
      "Current loss: 2.142701, [19200/60000]\n",
      "Current loss: 2.108447, [25600/60000]\n",
      "Current loss: 2.043516, [32000/60000]\n",
      "Current loss: 2.071839, [38400/60000]\n",
      "Current loss: 1.999627, [44800/60000]\n",
      "Current loss: 1.996043, [51200/60000]\n",
      "Current loss: 1.941233, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 54.5%, Avg loss: 1.934662\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "Current loss: 1.962199, [    0/60000]\n",
      "Current loss: 1.942914, [ 6400/60000]\n",
      "Current loss: 1.824689, [12800/60000]\n",
      "Current loss: 1.864606, [19200/60000]\n",
      "Current loss: 1.775136, [25600/60000]\n",
      "Current loss: 1.708919, [32000/60000]\n",
      "Current loss: 1.733051, [38400/60000]\n",
      "Current loss: 1.635983, [44800/60000]\n",
      "Current loss: 1.651387, [51200/60000]\n",
      "Current loss: 1.559673, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 58.9%, Avg loss: 1.570516\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "Current loss: 1.632005, [    0/60000]\n",
      "Current loss: 1.604176, [ 6400/60000]\n",
      "Current loss: 1.449572, [12800/60000]\n",
      "Current loss: 1.522830, [19200/60000]\n",
      "Current loss: 1.418367, [25600/60000]\n",
      "Current loss: 1.391821, [32000/60000]\n",
      "Current loss: 1.407935, [38400/60000]\n",
      "Current loss: 1.333374, [44800/60000]\n",
      "Current loss: 1.357318, [51200/60000]\n",
      "Current loss: 1.267984, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 62.9%, Avg loss: 1.291813\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "Current loss: 1.365933, [    0/60000]\n",
      "Current loss: 1.351893, [ 6400/60000]\n",
      "Current loss: 1.182507, [12800/60000]\n",
      "Current loss: 1.289349, [19200/60000]\n",
      "Current loss: 1.174355, [25600/60000]\n",
      "Current loss: 1.181612, [32000/60000]\n",
      "Current loss: 1.201934, [38400/60000]\n",
      "Current loss: 1.142246, [44800/60000]\n",
      "Current loss: 1.168078, [51200/60000]\n",
      "Current loss: 1.093002, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 64.7%, Avg loss: 1.114047\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "Current loss: 1.185053, [    0/60000]\n",
      "Current loss: 1.188546, [ 6400/60000]\n",
      "Current loss: 1.002528, [12800/60000]\n",
      "Current loss: 1.139740, [19200/60000]\n",
      "Current loss: 1.017104, [25600/60000]\n",
      "Current loss: 1.038655, [32000/60000]\n",
      "Current loss: 1.071849, [38400/60000]\n",
      "Current loss: 1.018607, [44800/60000]\n",
      "Current loss: 1.043655, [51200/60000]\n",
      "Current loss: 0.981674, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 65.9%, Avg loss: 0.997482\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "Current loss: 1.058171, [    0/60000]\n",
      "Current loss: 1.080996, [ 6400/60000]\n",
      "Current loss: 0.878195, [12800/60000]\n",
      "Current loss: 1.039824, [19200/60000]\n",
      "Current loss: 0.915783, [25600/60000]\n",
      "Current loss: 0.937383, [32000/60000]\n",
      "Current loss: 0.986640, [38400/60000]\n",
      "Current loss: 0.938010, [44800/60000]\n",
      "Current loss: 0.957432, [51200/60000]\n",
      "Current loss: 0.908101, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 67.2%, Avg loss: 0.918240\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "Current loss: 0.964732, [    0/60000]\n",
      "Current loss: 1.006820, [ 6400/60000]\n",
      "Current loss: 0.789948, [12800/60000]\n",
      "Current loss: 0.969765, [19200/60000]\n",
      "Current loss: 0.848834, [25600/60000]\n",
      "Current loss: 0.863368, [32000/60000]\n",
      "Current loss: 0.927580, [38400/60000]\n",
      "Current loss: 0.885170, [44800/60000]\n",
      "Current loss: 0.896011, [51200/60000]\n",
      "Current loss: 0.856499, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 68.5%, Avg loss: 0.862173\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "Current loss: 0.893696, [    0/60000]\n",
      "Current loss: 0.952475, [ 6400/60000]\n",
      "Current loss: 0.725482, [12800/60000]\n",
      "Current loss: 0.918360, [19200/60000]\n",
      "Current loss: 0.802665, [25600/60000]\n",
      "Current loss: 0.808137, [32000/60000]\n",
      "Current loss: 0.883585, [38400/60000]\n",
      "Current loss: 0.849107, [44800/60000]\n",
      "Current loss: 0.850919, [51200/60000]\n",
      "Current loss: 0.817796, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 69.9%, Avg loss: 0.820515\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "Current loss: 0.837590, [    0/60000]\n",
      "Current loss: 0.910078, [ 6400/60000]\n",
      "Current loss: 0.676406, [12800/60000]\n",
      "Current loss: 0.879180, [19200/60000]\n",
      "Current loss: 0.769007, [25600/60000]\n",
      "Current loss: 0.766228, [32000/60000]\n",
      "Current loss: 0.848321, [38400/60000]\n",
      "Current loss: 0.823262, [44800/60000]\n",
      "Current loss: 0.816574, [51200/60000]\n",
      "Current loss: 0.787197, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 71.0%, Avg loss: 0.788003\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "Current loss: 0.791801, [    0/60000]\n",
      "Current loss: 0.874915, [ 6400/60000]\n",
      "Current loss: 0.637548, [12800/60000]\n",
      "Current loss: 0.848550, [19200/60000]\n",
      "Current loss: 0.743101, [25600/60000]\n",
      "Current loss: 0.733514, [32000/60000]\n",
      "Current loss: 0.818538, [38400/60000]\n",
      "Current loss: 0.803457, [44800/60000]\n",
      "Current loss: 0.789313, [51200/60000]\n",
      "Current loss: 0.761887, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 72.2%, Avg loss: 0.761433\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "Current loss: 0.753404, [    0/60000]\n",
      "Current loss: 0.844601, [ 6400/60000]\n",
      "Current loss: 0.605707, [12800/60000]\n",
      "Current loss: 0.823523, [19200/60000]\n",
      "Current loss: 0.722055, [25600/60000]\n",
      "Current loss: 0.707394, [32000/60000]\n",
      "Current loss: 0.792467, [38400/60000]\n",
      "Current loss: 0.787022, [44800/60000]\n",
      "Current loss: 0.766840, [51200/60000]\n",
      "Current loss: 0.740060, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 73.5%, Avg loss: 0.738781\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "Current loss: 0.720232, [    0/60000]\n",
      "Current loss: 0.817666, [ 6400/60000]\n",
      "Current loss: 0.578649, [12800/60000]\n",
      "Current loss: 0.802275, [19200/60000]\n",
      "Current loss: 0.704296, [25600/60000]\n",
      "Current loss: 0.685913, [32000/60000]\n",
      "Current loss: 0.768869, [38400/60000]\n",
      "Current loss: 0.772500, [44800/60000]\n",
      "Current loss: 0.747624, [51200/60000]\n",
      "Current loss: 0.720572, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 74.4%, Avg loss: 0.718787\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "Current loss: 0.690967, [    0/60000]\n",
      "Current loss: 0.793230, [ 6400/60000]\n",
      "Current loss: 0.555087, [12800/60000]\n",
      "Current loss: 0.783701, [19200/60000]\n",
      "Current loss: 0.689029, [25600/60000]\n",
      "Current loss: 0.667671, [32000/60000]\n",
      "Current loss: 0.747145, [38400/60000]\n",
      "Current loss: 0.759350, [44800/60000]\n",
      "Current loss: 0.730762, [51200/60000]\n",
      "Current loss: 0.703072, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 75.1%, Avg loss: 0.700804\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "Current loss: 0.664793, [    0/60000]\n",
      "Current loss: 0.770759, [ 6400/60000]\n",
      "Current loss: 0.534316, [12800/60000]\n",
      "Current loss: 0.767149, [19200/60000]\n",
      "Current loss: 0.675648, [25600/60000]\n",
      "Current loss: 0.652123, [32000/60000]\n",
      "Current loss: 0.727111, [38400/60000]\n",
      "Current loss: 0.747431, [44800/60000]\n",
      "Current loss: 0.716006, [51200/60000]\n",
      "Current loss: 0.687192, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 75.8%, Avg loss: 0.684421\n",
      "\n",
      "Epoch 16\n",
      "\n",
      "Current loss: 0.641372, [    0/60000]\n",
      "Current loss: 0.750055, [ 6400/60000]\n",
      "Current loss: 0.515821, [12800/60000]\n",
      "Current loss: 0.752144, [19200/60000]\n",
      "Current loss: 0.663913, [25600/60000]\n",
      "Current loss: 0.638672, [32000/60000]\n",
      "Current loss: 0.708499, [38400/60000]\n",
      "Current loss: 0.736563, [44800/60000]\n",
      "Current loss: 0.703053, [51200/60000]\n",
      "Current loss: 0.672662, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 76.5%, Avg loss: 0.669426\n",
      "\n",
      "Epoch 17\n",
      "\n",
      "Current loss: 0.620389, [    0/60000]\n",
      "Current loss: 0.731073, [ 6400/60000]\n",
      "Current loss: 0.499260, [12800/60000]\n",
      "Current loss: 0.738272, [19200/60000]\n",
      "Current loss: 0.653619, [25600/60000]\n",
      "Current loss: 0.626978, [32000/60000]\n",
      "Current loss: 0.691249, [38400/60000]\n",
      "Current loss: 0.726673, [44800/60000]\n",
      "Current loss: 0.691609, [51200/60000]\n",
      "Current loss: 0.659288, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 77.2%, Avg loss: 0.655655\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "Current loss: 0.601526, [    0/60000]\n",
      "Current loss: 0.713570, [ 6400/60000]\n",
      "Current loss: 0.484294, [12800/60000]\n",
      "Current loss: 0.725365, [19200/60000]\n",
      "Current loss: 0.644449, [25600/60000]\n",
      "Current loss: 0.616617, [32000/60000]\n",
      "Current loss: 0.675242, [38400/60000]\n",
      "Current loss: 0.717776, [44800/60000]\n",
      "Current loss: 0.681589, [51200/60000]\n",
      "Current loss: 0.646973, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 77.7%, Avg loss: 0.642981\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "Current loss: 0.584501, [    0/60000]\n",
      "Current loss: 0.697463, [ 6400/60000]\n",
      "Current loss: 0.470778, [12800/60000]\n",
      "Current loss: 0.713419, [19200/60000]\n",
      "Current loss: 0.636268, [25600/60000]\n",
      "Current loss: 0.607367, [32000/60000]\n",
      "Current loss: 0.660390, [38400/60000]\n",
      "Current loss: 0.709840, [44800/60000]\n",
      "Current loss: 0.672823, [51200/60000]\n",
      "Current loss: 0.635449, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 78.3%, Avg loss: 0.631297\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "Current loss: 0.569073, [    0/60000]\n",
      "Current loss: 0.682529, [ 6400/60000]\n",
      "Current loss: 0.458499, [12800/60000]\n",
      "Current loss: 0.702233, [19200/60000]\n",
      "Current loss: 0.628777, [25600/60000]\n",
      "Current loss: 0.599100, [32000/60000]\n",
      "Current loss: 0.646607, [38400/60000]\n",
      "Current loss: 0.703075, [44800/60000]\n",
      "Current loss: 0.665316, [51200/60000]\n",
      "Current loss: 0.624583, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 78.7%, Avg loss: 0.620534\n",
      "\n",
      "Epoch 21\n",
      "\n",
      "Current loss: 0.554887, [    0/60000]\n",
      "Current loss: 0.668623, [ 6400/60000]\n",
      "Current loss: 0.447319, [12800/60000]\n",
      "Current loss: 0.691837, [19200/60000]\n",
      "Current loss: 0.622082, [25600/60000]\n",
      "Current loss: 0.591635, [32000/60000]\n",
      "Current loss: 0.633871, [38400/60000]\n",
      "Current loss: 0.697303, [44800/60000]\n",
      "Current loss: 0.658751, [51200/60000]\n",
      "Current loss: 0.614377, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 79.0%, Avg loss: 0.610643\n",
      "\n",
      "Epoch 22\n",
      "\n",
      "Current loss: 0.542007, [    0/60000]\n",
      "Current loss: 0.655804, [ 6400/60000]\n",
      "Current loss: 0.436991, [12800/60000]\n",
      "Current loss: 0.682046, [19200/60000]\n",
      "Current loss: 0.615841, [25600/60000]\n",
      "Current loss: 0.584773, [32000/60000]\n",
      "Current loss: 0.622139, [38400/60000]\n",
      "Current loss: 0.692332, [44800/60000]\n",
      "Current loss: 0.653117, [51200/60000]\n",
      "Current loss: 0.604718, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 79.3%, Avg loss: 0.601520\n",
      "\n",
      "Epoch 23\n",
      "\n",
      "Current loss: 0.530141, [    0/60000]\n",
      "Current loss: 0.643935, [ 6400/60000]\n",
      "Current loss: 0.427479, [12800/60000]\n",
      "Current loss: 0.672832, [19200/60000]\n",
      "Current loss: 0.609981, [25600/60000]\n",
      "Current loss: 0.578437, [32000/60000]\n",
      "Current loss: 0.611322, [38400/60000]\n",
      "Current loss: 0.688262, [44800/60000]\n",
      "Current loss: 0.648188, [51200/60000]\n",
      "Current loss: 0.595384, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 79.5%, Avg loss: 0.593100\n",
      "\n",
      "Epoch 24\n",
      "\n",
      "Current loss: 0.519253, [    0/60000]\n",
      "Current loss: 0.632887, [ 6400/60000]\n",
      "Current loss: 0.418792, [12800/60000]\n",
      "Current loss: 0.664135, [19200/60000]\n",
      "Current loss: 0.604395, [25600/60000]\n",
      "Current loss: 0.572521, [32000/60000]\n",
      "Current loss: 0.601383, [38400/60000]\n",
      "Current loss: 0.684975, [44800/60000]\n",
      "Current loss: 0.643963, [51200/60000]\n",
      "Current loss: 0.586350, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 79.7%, Avg loss: 0.585329\n",
      "\n",
      "Epoch 25\n",
      "\n",
      "Current loss: 0.509105, [    0/60000]\n",
      "Current loss: 0.622602, [ 6400/60000]\n",
      "Current loss: 0.410799, [12800/60000]\n",
      "Current loss: 0.655976, [19200/60000]\n",
      "Current loss: 0.598818, [25600/60000]\n",
      "Current loss: 0.566979, [32000/60000]\n",
      "Current loss: 0.592155, [38400/60000]\n",
      "Current loss: 0.682433, [44800/60000]\n",
      "Current loss: 0.640344, [51200/60000]\n",
      "Current loss: 0.577637, [57600/60000]\n",
      "Test Error:\n",
      " Accuracy: 79.9%, Avg loss: 0.578132\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "optimize_loop(plot_x, plot_y, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (main, Jan 25 2022, 07:39:16) [Clang 13.0.0 (clang-1300.0.27.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d89c39eb4a984fcf43ceca0b8c5be43979e9b8f7a2029ea8a54f4a0f5b2e7ef9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
